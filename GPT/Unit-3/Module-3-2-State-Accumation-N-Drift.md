### ðŸ§© **Submodule 3.2.1: Why Agents â€œGo Off the Railsâ€**

This is **the bug** behind 90% of bad agents.

---

## ðŸŸ¢ Mental Model (plain English)

An agent **drifts** when:

> It keeps remembering things  
> that were never meant to matter again.

Thatâ€™s it. No mystery.

---

## ðŸ”µ What â€œstate accumulationâ€ actually means

State accumulation =  
**state growing over time without discipline**

Not in size only â€” in _meaning_.

The system starts carrying:

- old assumptions
    
- rejected ideas
    
- outdated interpretations
    
- failed attempts
    

Eventually, the agent is reasoning about a **fictional world**.

---

## ðŸ§ª Concrete example (your exact scenario)

Letâ€™s say the agent does this:

1. Draft v1 â†’ rejected
    
2. Draft v2 â†’ rejected
    
3. Draft v3 â†’ user edits and clarifies intent
    

### âŒ Bad agent memory
```
- draft_v1: said X
- draft_v2: said Y
- user maybe wants X/Y?
```
Now the agent:

- hesitates
    
- contradicts itself
    
- argues with the user
    

This is **drift**.

### âœ… Correct memory discipline
```
- current_draft = draft_v3
- decision: previous attempts failed
- decision: user clarified intent
```
Old drafts are **dead**.  
They do not participate in future reasoning.

---

## ðŸ”´ Where drift comes from (very specific)

Drift happens when you persist:

1. âŒ **Rejected artifacts**
    
2. âŒ **LLM reasoning**
    
3. âŒ **Tool paths**
    
4. âŒ **Intermediate interpretations**
    
5. âŒ **Unapproved inferences**
    

These _feel_ useful but are toxic long-term.

---

## ðŸŸ£ Why this breaks agents badly

Once drift starts:

- every new decision is biased
    
- the agent defends past mistakes
    
- â€œmemoryâ€ feels like stubbornness
    

Users say:

> â€œWhy do you keep going back to that?â€

Because the system **never forgot**.

---

## ðŸ”’ The invariant that prevents drift

Write this down. This is the rule.

> **State may only grow by decisions,  
> never by attempts.**

Attempts are disposable.  
Decisions are durable.

---

## ðŸ› ï¸ How professionals prevent drift (no code)

They do **three things**:

1. **Overwrite artifacts**
    
    - Only one â€œcurrentâ€ draft exists
        
2. **Summarize failures**
    
    - â€œAttempt failed due to Xâ€ (one line)
        
3. **Freeze decisions**
    
    - Explicit user approvals are sacred
        

Thatâ€™s it.

No fancy memory systems required.

---

## ðŸš§ MINI CHECK (answer mentally)

Which of these should survive **10 iterations**?

- â“ â€œDraft #2 textâ€
    
- â“ â€œUser wants formal toneâ€
    
- â“ â€œTool call failed due to timeoutâ€
    
- â“ â€œReasoning about why draft #1 was badâ€

### âœ… The one that should survive 10 iterations

**â€œUser wants formal toneâ€**

Why?

- Itâ€™s a **decision**
    
- It constrains future behavior
    
- Losing it breaks correctness
    
- Repeating it doesnâ€™t cause drift
    

This is **decision memory**.

---

### âŒ The others should NOT survive

- **Draft #2 text** â†’ rejected artifact
    
- **Tool call failed due to timeout** â†’ transient event (maybe summarized once, then gone)
    
- **Reasoning about why draft #1 was bad** â†’ ephemeral thinking
    

Keeping those causes:

- bias
    
- stubbornness
    
- â€œwhy are you bringing that up again?â€
    

---

### One-line rule (final)

> **Persist user intent, not your attempts.**

### ðŸ§© **Submodule 3.2.2: Memory Pruning & Checkpoints**

This submodule exists because **perfect memory is a bug**.

---

## ðŸŸ¢ Mental Model (very simple)

An agent must do **two opposite things well**:

1. **Remember what matters**
    
2. **Forget everything else**
    

Memory pruning and checkpoints are how you enforce that **on purpose**, not by accident.

---

## ðŸ”µ Why this exists (real-world failure)

Agents fail when:

- memory only grows
    
- nothing ever gets deleted
    
- every iteration adds â€œjust one more thingâ€
    

Eventually:

- reasoning slows
    
- bias compounds
    
- wrong assumptions become permanent
    
- restarting becomes the only fix
    

Thatâ€™s not intelligence failure.  
Thatâ€™s **memory hygiene failure**.

---

## ðŸŸ£ Memory Pruning (what it really means)

**Memory pruning** is:

> Deliberately deleting or overwriting state  
> that is no longer allowed to influence decisions.

Key word: **allowed**.

This is not â€œgarbage collectionâ€.  
This is **policy**.

---

### What SHOULD be pruned (aggressively)

âŒ Old drafts  
âŒ Failed attempts  
âŒ Intermediate tool outputs  
âŒ LLM reasoning  
âŒ Temporary interpretations

These must **not survive loops**.

If they do â†’ drift.

---

### What should NEVER be pruned automatically

âœ… User-approved decisions  
âœ… Explicit constraints  
âœ… Control state (`cnt`, `status`)  
âœ… Final artifacts

These are **authoritative**.

---

## ðŸ§ª Concrete example (your system)

Each loop iteration should conceptually do this:
```
Before next iteration:
- overwrite draft
- discard old reasoning
- keep only:
    - current draft
    - decision summary
    - control state
```
If you donâ€™t do this explicitly, the agent will not â€œfigure it outâ€.

---

## ðŸŸ£ Checkpoints (the second half)

A **checkpoint** is:

> A trusted snapshot of state  
> that you can safely resume from.

Think of it as:

- â€œthis is a known-good pointâ€
    
- â€œeverything before this is settledâ€
    

---

### Why checkpoints matter

They allow:

- pause & resume
    
- crash recovery
    
- human intervention
    
- safe rollback
    

Without checkpoints:

- long-running agents are fragile
    
- restarts lose intent
    
- bugs force full resets
    

---

## ðŸ§ª Checkpoint vs memory (clear distinction)

- **Memory** â†’ what the agent _uses_
    
- **Checkpoint** â†’ what the system _trusts_
    

You may prune memory **between** checkpoints.  
You may **never** violate a checkpoint silently.

---

## ðŸ”’ Critical invariant (write this)

> **Only checkpointed state may survive interruption.**

Everything else is optional.

---

## ðŸ› ï¸ Professional pattern (no code)

Systems often do:

- Checkpoint on:
    
    - user approval
        
    - successful completion
        
    - escalation boundary
        
- Prune aggressively between checkpoints
    
- Resume only from checkpoints, never from â€œhalf-thoughtsâ€
    

This is how:

- CI systems work
    
- distributed jobs work
    
- databases work
    

Agents are no different.

---

## ðŸš§ MINI PROJECT (MENTAL, IMPORTANT)

For your system, answer:

1. When is it safe to create a checkpoint?
    
2. What exact state must be in that checkpoint?
    
3. What state must **never** be checkpointed?
    

If you can answer this, you fully understand memory discipline.

---

## ðŸ”‘ Sentence to lock this forever

> **Good agents forget constantly,  
> but remember deliberately.**

### 1ï¸âƒ£ When is it safe to create a checkpoint?

**Correct answer:**

- After a **user-approved decision**
    
- After a **goal is explicitly satisfied**
    
- At a **clean escalation boundary**
    

In other words:

> When you are confident  
> the system may resume from here  
> without reinterpreting the past.

Not â€œwhen user says soâ€ blindly â€”  
but when **authority is established**.

---

### 2ï¸âƒ£ What must be in a checkpoint?

**Minimum checkpoint = control truth**

Example:
```
status
cnt
max
current_draft
explicit user constraints
```

Checkpoint does **not** store:

- reasoning
    
- tool traces
    
- alternatives
    

Just enough to **resume correctly**.

---

### 3ï¸âƒ£ What must never be checkpointed?

Now this should be clear:

âŒ Intermediate reasoning  
âŒ Failed attempts  
âŒ Old drafts  
âŒ Temporary interpretations

These may exist in **archive**, but never in a checkpoint.

Checkpoint = trust boundary.

---

## One sentence that unifies everything (very important)

> **State decides.  
> Archive explains.  
> Checkpoints resume.**

If you keep those three separate, you will never get lost.